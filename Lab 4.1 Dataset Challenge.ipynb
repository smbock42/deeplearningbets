{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ys8EJg7PLYyC"
   },
   "source": [
    "I chose to make a model that takes in 5 years of stock data and will decide whether to buy, sell, or hold that stock position.\n",
    "\n",
    "I am comparing a baseline Linear NN with two more advanced models to see whether predictions and accuracy improve with more complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qCSqD4IkoN2c",
    "outputId": "e9603afe-704c-4eee-bfbd-7044493661ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.13/site-packages (2.2.4)\n",
      "Requirement already satisfied: yfinance in ./.venv/lib/python3.13/site-packages (0.2.54)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.13/site-packages (1.6.1)\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.13/site-packages (2.6.0)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.13/site-packages (3.10.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.13/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.13/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: requests>=2.31 in ./.venv/lib/python3.13/site-packages (from yfinance) (2.32.3)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in ./.venv/lib/python3.13/site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in ./.venv/lib/python3.13/site-packages (from yfinance) (4.3.6)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in ./.venv/lib/python3.13/site-packages (from yfinance) (2.4.6)\n",
      "Requirement already satisfied: peewee>=3.16.2 in ./.venv/lib/python3.13/site-packages (from yfinance) (3.17.9)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in ./.venv/lib/python3.13/site-packages (from yfinance) (4.13.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.13/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.13/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from torch) (76.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.13/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.13/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.13/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.13/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.13/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.13/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests>=2.31->yfinance) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests>=2.31->yfinance) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests>=2.31->yfinance) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests>=2.31->yfinance) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy yfinance scikit-learn torch matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "M7dIjfD-oZ4d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lWTCy2kf1mPs"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'ticker': 'TSLA',\n",
    "    'benchmark': '^GSPC',\n",
    "    'start_date': '2020-01-01',\n",
    "    'end_date': '2025-03-15',\n",
    "    'seq_length': 30,\n",
    "    'batch_size': 64,\n",
    "    'hidden_size': 128,\n",
    "    'num_layers': 3,\n",
    "    'dropout': 0.4,\n",
    "    'num_epochs': 200,\n",
    "    'learning_rate': 0.0005,\n",
    "    'train_ratio': 0.8\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AD6fo7RWMi6B"
   },
   "source": [
    "# Choose Stock and Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "93iUROsfiq6T"
   },
   "outputs": [],
   "source": [
    "def fetch_and_preprocess_data():\n",
    "    \"\"\"Fetch and preprocess data with enhanced technical indicators\"\"\"\n",
    "    # Fetch data\n",
    "    stock = yf.download(config['ticker'], start=config['start_date'], end=config['end_date'])\n",
    "    bench = yf.download(config['benchmark'], start=config['start_date'], end=config['end_date'])\n",
    "\n",
    "    # Calculate features\n",
    "    df = stock[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
    "    df['Bench_Close'] = bench['Close']\n",
    "\n",
    "    # Technical indicators - original ones\n",
    "    df['SMA_20'] = df['Close'].rolling(20).mean()\n",
    "    df['EMA_20'] = df['Close'].ewm(span=20, adjust=False).mean()\n",
    "    df['RSI'] = calculate_rsi(df['Close'])\n",
    "    df['MACD'] = calculate_macd(df['Close'])\n",
    "    df['ATR'] = calculate_atr(df)\n",
    "    df['OBV'] = calculate_obv(df)\n",
    "\n",
    "    # Additional technical indicators\n",
    "    df['BB_Upper'], df['BB_Middle'], df['BB_Lower'] = calculate_bollinger_bands(df['Close'])\n",
    "    df['Stoch_K'], df['Stoch_D'] = calculate_stochastic_oscillator(df)\n",
    "    df['ADX'] = calculate_adx(df)\n",
    "    df['Daily_Return'] = df['Close'].pct_change() * 100\n",
    "    df['Volatility_21'] = df['Daily_Return'].rolling(21).std()\n",
    "    df['Price_to_SMA_20'] = df['Close'] / df['SMA_20']\n",
    "    df['Bench_Return'] = bench['Close'].pct_change() * 100\n",
    "    df['Volume_Change'] = df['Volume'].pct_change() * 100\n",
    "    df['High_Low_Ratio'] = df['High'] / df['Low']\n",
    "    df['SMA_50'] = df['Close'].rolling(50).mean()\n",
    "    df['EMA_50'] = df['Close'].ewm(span=50, adjust=False).mean()\n",
    "\n",
    "    # Price momentum features\n",
    "    df['Price_Momentum_5'] = df['Close'].pct_change(5) * 100\n",
    "    df['Price_Momentum_10'] = df['Close'].pct_change(10) * 100\n",
    "    df['Price_Momentum_20'] = df['Close'].pct_change(20) * 100\n",
    "\n",
    "    # Target: Next day's percentage change\n",
    "    df['Target'] = ((df['Close'].shift(-1) - df['Close']) / df['Close']) * 100\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    df.columns = df.columns.get_level_values(0)\n",
    "\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z_9VX-RY1taP"
   },
   "outputs": [],
   "source": [
    "def calculate_rsi(series, window=14):\n",
    "    \"\"\"Relative Strength Index\"\"\"\n",
    "    delta = series.diff()\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "\n",
    "    avg_gain = gain.rolling(window).mean()\n",
    "    avg_loss = loss.rolling(window).mean()\n",
    "\n",
    "    rs = avg_gain / avg_loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "def calculate_macd(series, fast=12, slow=26, signal=9):\n",
    "    \"\"\"MACD Indicator\"\"\"\n",
    "    ema_fast = series.ewm(span=fast, adjust=False).mean()\n",
    "    ema_slow = series.ewm(span=slow, adjust=False).mean()\n",
    "    macd = ema_fast - ema_slow\n",
    "    return macd.ewm(span=signal, adjust=False).mean()\n",
    "\n",
    "def calculate_atr(df, window=14):\n",
    "    \"\"\"Average True Range\"\"\"\n",
    "    high_low = df['High'] - df['Low']\n",
    "    high_close = (df['High'] - df['Close'].shift()).abs()\n",
    "    low_close = (df['Low'] - df['Close'].shift()).abs()\n",
    "    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
    "    return tr.rolling(window).mean()\n",
    "\n",
    "def calculate_obv(df):\n",
    "    \"\"\"On-Balance Volume\"\"\"\n",
    "    obv = (np.sign(df['Close'].diff()) * df['Volume']).cumsum()\n",
    "    return obv\n",
    "\n",
    "def calculate_bollinger_bands(close, window=20, num_std=2):\n",
    "    \"\"\"Calculate Bollinger Bands\"\"\"\n",
    "    sma = close.rolling(window).mean()\n",
    "    std = close.rolling(window).std()\n",
    "    upper = sma + (std * num_std)\n",
    "    lower = sma - (std * num_std)\n",
    "    return upper, sma, lower\n",
    "\n",
    "def calculate_stochastic_oscillator(df, k_window=14, d_window=3):\n",
    "    \"\"\"Calculate Stochastic Oscillator\"\"\"\n",
    "    low_min = df['Low'].rolling(k_window).min()\n",
    "    high_max = df['High'].rolling(k_window).max()\n",
    "\n",
    "    # Calculate %K\n",
    "    k = 100 * ((df['Close'] - low_min) / (high_max - low_min))\n",
    "\n",
    "    # Calculate %D\n",
    "    d = k.rolling(d_window).mean()\n",
    "\n",
    "    return k, d\n",
    "\n",
    "def calculate_adx(df, window=14):\n",
    "    \"\"\"Average Directional Index\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # True Range\n",
    "    df['TR'] = calculate_atr(df, 1)\n",
    "\n",
    "    # +DM and -DM\n",
    "    df['High_Shift'] = df['High'].shift(1)\n",
    "    df['Low_Shift'] = df['Low'].shift(1)\n",
    "\n",
    "    # Directional Movement\n",
    "    df['+DM'] = np.where((df['High'] - df['High_Shift']) > (df['Low_Shift'] - df['Low']), \n",
    "                         np.maximum(df['High'] - df['High_Shift'], 0), 0)\n",
    "    df['-DM'] = np.where((df['Low_Shift'] - df['Low']) > (df['High'] - df['High_Shift']),\n",
    "                        np.maximum(df['Low_Shift'] - df['Low'], 0), 0)\n",
    "\n",
    "    # Smoothed values\n",
    "    df['+DI'] = 100 * (df['+DM'].rolling(window).sum() / df['TR'].rolling(window).sum())\n",
    "    df['-DI'] = 100 * (df['-DM'].rolling(window).sum() / df['TR'].rolling(window).sum())\n",
    "\n",
    "    # Directional Index\n",
    "    df['DX'] = 100 * (abs(df['+DI'] - df['-DI']) / (df['+DI'] + df['-DI']))\n",
    "\n",
    "    # Average Directional Index\n",
    "    adx = df['DX'].rolling(window).mean()\n",
    "\n",
    "    return adx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "vvHIovQM1w2_"
   },
   "outputs": [],
   "source": [
    "def create_sequences(data, target, seq_length):\n",
    "    \"\"\"Create time series sequences\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(target[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jyjXtkaG1z0D"
   },
   "outputs": [],
   "source": [
    "class EnhancedLSTM(nn.Module):\n",
    "    \"\"\"LSTM model with regularization and deep architecture\"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers,\n",
    "                           batch_first=True, dropout=dropout)\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 64),\n",
    "            nn.LayerNorm(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        attn_weights = self.attention(out)\n",
    "        context = torch.sum(attn_weights * out, dim=1)\n",
    "        return self.fc(context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "uDRzsBZU14Na"
   },
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    # Data preparation\n",
    "    df = fetch_and_preprocess_data()\n",
    "    features = df.columns.drop('Target').tolist()\n",
    "    target = df['Target'].values\n",
    "\n",
    "    # Scaling\n",
    "    scaler = RobustScaler()\n",
    "    scaled_features = scaler.fit_transform(df[features])\n",
    "\n",
    "    # Sequence creation\n",
    "    X, y = create_sequences(scaled_features, target, config['seq_length'])\n",
    "\n",
    "    # Train-test split\n",
    "    split_idx = int(len(X) * config['train_ratio'])\n",
    "    X_train, y_train = X[:split_idx], y[:split_idx]\n",
    "    X_test, y_test = X[split_idx:], y[split_idx:]\n",
    "\n",
    "    # Convert to tensors\n",
    "    X_train = torch.FloatTensor(X_train)\n",
    "    y_train = torch.FloatTensor(y_train)\n",
    "    X_test = torch.FloatTensor(X_test)\n",
    "    y_test = torch.FloatTensor(y_test)\n",
    "\n",
    "    # Model setup\n",
    "    model = EnhancedLSTM(\n",
    "        input_size=X_train.shape[2],\n",
    "        hidden_size=config['hidden_size'],\n",
    "        num_layers=config['num_layers'],\n",
    "        dropout=config['dropout']\n",
    "    )\n",
    "    criterion = nn.HuberLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10)\n",
    "\n",
    "    # Training loop\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(config['num_epochs']):\n",
    "        model.train()\n",
    "        batch_loss = []\n",
    "        for i in range(0, len(X_train), config['batch_size']):\n",
    "            X_batch = X_train[i:i+config['batch_size']]\n",
    "            y_batch = y_train[i:i+config['batch_size']]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch).flatten()\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            batch_loss.append(loss.item())\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_preds = model(X_test).flatten()\n",
    "            test_loss = criterion(test_preds, y_test)\n",
    "            scheduler.step(test_loss)\n",
    "\n",
    "            # Metrics\n",
    "            mae = mean_absolute_error(y_test, test_preds)\n",
    "            rmse = np.sqrt(mean_squared_error(y_test, test_preds))\n",
    "            mape = np.mean(np.abs((y_test - test_preds) / np.abs(y_test))) * 100\n",
    "\n",
    "        if test_loss < best_loss:\n",
    "            best_loss = test_loss\n",
    "            torch.save(model.state_dict(), 'best_lstm_model.pth')\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{config['num_epochs']}\")\n",
    "            print(f\"Train Loss: {np.mean(batch_loss):.4f} | Test Loss: {test_loss:.4f}\")\n",
    "            print(f\"MAE: {mae:.2f}% | RMSE: {rmse:.2f}% | MAPE: {mape:.2f}%\\n\")\n",
    "\n",
    "    print(f\"Training complete. Best validation loss: {best_loss:.4f}\")\n",
    "    return model, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "zrsIwGPx18iD"
   },
   "outputs": [],
   "source": [
    "\n",
    "def predict_next_day(model, scaler, ticker, date):\n",
    "    \"\"\"Predict percentage change for next trading day\"\"\"\n",
    "    # Fetch latest data\n",
    "    end_date = pd.to_datetime(date)\n",
    "    start_date = end_date - pd.DateOffset(days=config['seq_length']*2)\n",
    "\n",
    "    stock = yf.download(ticker, start=start_date, end=end_date)\n",
    "    bench = yf.download(config['benchmark'], start=start_date, end=end_date)\n",
    "\n",
    "    # Preprocess\n",
    "    df = stock[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
    "    df['Bench_Close'] = bench['Close']\n",
    "\n",
    "    # Add technical indicators\n",
    "    df = df.join(pd.DataFrame({\n",
    "        'SMA_20': df['Close'].rolling(20).mean(),\n",
    "        'EMA_20': df['Close'].ewm(span=20, adjust=False).mean(),\n",
    "        'RSI': calculate_rsi(df['Close']),\n",
    "        'MACD': calculate_macd(df['Close']),\n",
    "        'ATR': calculate_atr(df),\n",
    "        'OBV': calculate_obv(df)\n",
    "    }))\n",
    "\n",
    "    # Get last sequence\n",
    "    seq = df.iloc[-config['seq_length']:][features]\n",
    "    seq_scaled = scaler.transform(seq)\n",
    "\n",
    "    # Predict\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        prediction = model(torch.FloatTensor(seq_scaled).unsqueeze(0)).item()\n",
    "\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPsP13_b1-RU"
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525
    },
    "id": "uJLMgLso1_pK",
    "outputId": "292977c1-8811-4fde-a135-b046b17921c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/c5/pqhrqmsx7tz5mnlm4zl04z840000gn/T/ipykernel_4131/1498041748.py:63: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  mape = np.mean(np.abs((y_test - test_preds) / np.abs(y_test))) * 100\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "mean() received an invalid combination of arguments - got (out=NoneType, dtype=NoneType, axis=NoneType, ), but expected one of:\n * (*, torch.dtype dtype = None)\n * (tuple of ints dim, bool keepdim = False, *, torch.dtype dtype = None)\n * (tuple of names dim, bool keepdim = False, *, torch.dtype dtype = None)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m trained_model, feature_scaler = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Example prediction\u001b[39;00m\n\u001b[32m      4\u001b[39m prediction_date = \u001b[33m'\u001b[39m\u001b[33m2025-03-16\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 63\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     61\u001b[39m     mae = mean_absolute_error(y_test, test_preds)\n\u001b[32m     62\u001b[39m     rmse = np.sqrt(mean_squared_error(y_test, test_preds))\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     mape = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_preds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m * \u001b[32m100\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m test_loss < best_loss:\n\u001b[32m     66\u001b[39m     best_loss = test_loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/deeplearningbets/.venv/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:3858\u001b[39m, in \u001b[36mmean\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, where)\u001b[39m\n\u001b[32m   3856\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   3857\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3858\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3860\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[32m   3861\u001b[39m                       out=out, **kwargs)\n",
      "\u001b[31mTypeError\u001b[39m: mean() received an invalid combination of arguments - got (out=NoneType, dtype=NoneType, axis=NoneType, ), but expected one of:\n * (*, torch.dtype dtype = None)\n * (tuple of ints dim, bool keepdim = False, *, torch.dtype dtype = None)\n * (tuple of names dim, bool keepdim = False, *, torch.dtype dtype = None)\n"
     ]
    }
   ],
   "source": [
    "trained_model, feature_scaler = train_model()\n",
    "\n",
    "# Example prediction\n",
    "prediction_date = '2025-03-16'\n",
    "pred_pct = predict_next_day(trained_model, feature_scaler,\n",
    "                        config['ticker'], prediction_date)\n",
    "\n",
    "print(f\"\\nPredicted percentage change for {prediction_date}: {pred_pct:.2f}%\")\n",
    "print(\"Trading Recommendation:\")\n",
    "if pred_pct > 1.5:\n",
    "    print(\"Strong Buy\")\n",
    "elif pred_pct > 0.5:\n",
    "    print(\"Buy\")\n",
    "elif pred_pct < -1.5:\n",
    "    print(\"Strong Sell\")\n",
    "elif pred_pct < -0.5:\n",
    "    print(\"Sell\")\n",
    "else:\n",
    "    print(\"Hold\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(ticker, benchmark, start_date, end_date='2025-03-15', seq_length=30, train_ratio=0.8):\n",
    "    \"\"\"Prepare data for model training with proper feature engineering\"\"\"\n",
    "    # Fetch data\n",
    "    stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    benchmark_data = yf.download(benchmark, start=start_date, end=end_date)\n",
    "    \n",
    "    # Basic features\n",
    "    df = stock_data[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
    "    df['Bench_Close'] = benchmark_data['Close']\n",
    "    \n",
    "    # Technical indicators - original ones\n",
    "    df['SMA_20'] = df['Close'].rolling(20).mean()\n",
    "    df['EMA_20'] = df['Close'].ewm(span=20, adjust=False).mean()\n",
    "    df['RSI'] = calculate_rsi(df['Close'])\n",
    "    df['MACD'] = calculate_macd(df['Close'])\n",
    "    df['ATR'] = calculate_atr(df)\n",
    "    df['OBV'] = calculate_obv(df)\n",
    "    \n",
    "    # Additional technical indicators\n",
    "    df['BB_Upper'], df['BB_Middle'], df['BB_Lower'] = calculate_bollinger_bands(df['Close'])\n",
    "    df['Stoch_K'], df['Stoch_D'] = calculate_stochastic_oscillator(df)\n",
    "    df['ADX'] = calculate_adx(df)\n",
    "    df['Daily_Return'] = df['Close'].pct_change() * 100\n",
    "    df['Volatility_21'] = df['Daily_Return'].rolling(21).std()\n",
    "    df['Price_to_SMA_20'] = df['Close'] / df['SMA_20']\n",
    "    df['Bench_Return'] = df['Bench_Close'].pct_change() * 100\n",
    "    df['Volume_Change'] = df['Volume'].pct_change() * 100\n",
    "    df['High_Low_Ratio'] = df['High'] / df['Low']\n",
    "    df['SMA_50'] = df['Close'].rolling(50).mean()\n",
    "    df['EMA_50'] = df['Close'].ewm(span=50, adjust=False).mean()\n",
    "    \n",
    "    # Price momentum features\n",
    "    df['Price_Momentum_5'] = df['Close'].pct_change(5) * 100\n",
    "    df['Price_Momentum_10'] = df['Close'].pct_change(10) * 100\n",
    "    df['Price_Momentum_20'] = df['Close'].pct_change(20) * 100\n",
    "    \n",
    "    # Target: Next day's percentage change\n",
    "    df['Target'] = ((df['Close'].shift(-1) - df['Close']) / df['Close']) * 100\n",
    "    \n",
    "    # Drop NaN values\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    # Save Close prices for later visualization\n",
    "    close_prices = df['Close'].values\n",
    "    \n",
    "    # Features and target\n",
    "    features = df.drop('Target', axis=1)\n",
    "    feature_names = features.columns.tolist()\n",
    "    target = df['Target'].values\n",
    "    \n",
    "    # Scaling features\n",
    "    scaler = RobustScaler()\n",
    "    scaled_features = scaler.fit_transform(features)\n",
    "    \n",
    "    # Create sequences\n",
    "    X, y = create_sequences(scaled_features, target, seq_length)\n",
    "    \n",
    "    # Train-test split\n",
    "    split_idx = int(len(X) * train_ratio)\n",
    "    X_train, y_train = X[:split_idx], y[:split_idx]\n",
    "    X_test, y_test = X[split_idx:], y[split_idx:]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, scaler, feature_names, close_prices, df.index[seq_length:]\n",
    "\n",
    "def visualize_predictions(model, X_test, y_test, close_prices, dates):\n",
    "    \"\"\"Visualize actual vs predicted price changes and absolute prices\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.dates import DateFormatter\n",
    "    \n",
    "    # Get predictions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(torch.FloatTensor(X_test)).flatten().numpy()\n",
    "    \n",
    "    # Calculate the test date range\n",
    "    test_dates = dates[-len(y_test):]\n",
    "    \n",
    "    # Get the actual close prices for the test period\n",
    "    test_close = close_prices[-len(y_test)-1:]\n",
    "    \n",
    "    # Calculate the predicted prices\n",
    "    predicted_prices = []\n",
    "    actual_prices = []\n",
    "    \n",
    "    for i in range(len(predictions)):\n",
    "        # Calculate the predicted close price using the percentage change\n",
    "        pred_close = test_close[i] * (1 + predictions[i]/100)\n",
    "        actual_close = test_close[i] * (1 + y_test[i]/100)\n",
    "        \n",
    "        predicted_prices.append(pred_close)\n",
    "        actual_prices.append(actual_close)\n",
    "    \n",
    "    # Create a figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n",
    "    \n",
    "    # Plot percentage changes\n",
    "    ax1.plot(test_dates, y_test, label='Actual % Change', color='blue', alpha=0.7)\n",
    "    ax1.plot(test_dates, predictions, label='Predicted % Change', color='red', alpha=0.7)\n",
    "    ax1.set_title('Actual vs Predicted Price Changes (%)', fontsize=16)\n",
    "    ax1.set_ylabel('Percentage Change (%)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plot absolute prices\n",
    "    ax2.plot(test_dates, test_close[1:], label='Actual Close Price', color='blue', alpha=0.7)\n",
    "    ax2.plot(test_dates, predicted_prices, label='Predicted Close Price', color='red', alpha=0.7)\n",
    "    ax2.set_title('Actual vs Predicted Stock Price', fontsize=16)\n",
    "    ax2.set_xlabel('Date')\n",
    "    ax2.set_ylabel('Price ($)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    # Format x-axis dates\n",
    "    date_format = DateFormatter('%Y-%m-%d')\n",
    "    ax1.xaxis.set_major_formatter(date_format)\n",
    "    ax2.xaxis.set_major_formatter(date_format)\n",
    "    \n",
    "    # Rotate date labels for better readability\n",
    "    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)\n",
    "    plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "    mape = np.mean(np.abs((y_test - predictions) / (np.abs(y_test) + 1e-7))) * 100\n",
    "    \n",
    "    print(f\"Model Performance Metrics:\")\n",
    "    print(f\"MAE: {mae:.2f}% | RMSE: {rmse:.2f}% | MAPE: {mape:.2f}%\")\n",
    "\n",
    "# Main execution cells\n",
    "# Replace the train_model call and subsequent code with:\n",
    "\n",
    "# Prepare data\n",
    "X_train, y_train, X_test, y_test, scaler, feature_names, close_prices, dates = prepare_data(\n",
    "    ticker=config['ticker'],\n",
    "    benchmark=config['benchmark'],\n",
    "    start_date=config['start_date'],\n",
    "    seq_length=config['seq_length']\n",
    ")\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.FloatTensor(y_train)\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_test_tensor = torch.FloatTensor(y_test)\n",
    "\n",
    "# Model setup\n",
    "model = EnhancedLSTM(\n",
    "    input_size=X_train.shape[2],\n",
    "    hidden_size=config['hidden_size'],\n",
    "    num_layers=config['num_layers'],\n",
    "    dropout=config['dropout']\n",
    ")\n",
    "criterion = nn.HuberLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10)\n",
    "\n",
    "# Training loop\n",
    "best_loss = float('inf')\n",
    "for epoch in range(config['num_epochs']):\n",
    "    model.train()\n",
    "    batch_loss = []\n",
    "    for i in range(0, len(X_train), config['batch_size']):\n",
    "        X_batch = X_train_tensor[i:i+config['batch_size']]\n",
    "        y_batch = y_train_tensor[i:i+config['batch_size']]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch).flatten()\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        batch_loss.append(loss.item())\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_preds = model(X_test_tensor).flatten()\n",
    "        test_loss = criterion(test_preds, y_test_tensor)\n",
    "        scheduler.step(test_loss)\n",
    "        \n",
    "        # Metrics\n",
    "        mae = mean_absolute_error(y_test, test_preds.numpy())\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, test_preds.numpy()))\n",
    "        mape = np.mean(np.abs((y_test - test_preds.numpy()) / (np.abs(y_test) + 1e-7))) * 100\n",
    "    \n",
    "    if test_loss < best_loss:\n",
    "        best_loss = test_loss\n",
    "        torch.save(model.state_dict(), 'best_lstm_model.pth')\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{config['num_epochs']}\")\n",
    "        print(f\"Train Loss: {np.mean(batch_loss):.4f} | Test Loss: {test_loss:.4f}\")\n",
    "        print(f\"MAE: {mae:.2f}% | RMSE: {rmse:.2f}% | MAPE: {mape:.2f}%\\n\")\n",
    "\n",
    "print(f\"Training complete. Best validation loss: {best_loss:.4f}\")\n",
    "\n",
    "# Visualize the results\n",
    "visualize_predictions(model, X_test, y_test, close_prices, dates)\n",
    "\n",
    "# Example prediction\n",
    "prediction_date = '2025-03-16'\n",
    "pred_pct = predict_next_day(model, scaler, config['ticker'], prediction_date)\n",
    "\n",
    "print(f\"\\nPredicted percentage change for {prediction_date}: {pred_pct:.2f}%\")\n",
    "print(\"Trading Recommendation:\")\n",
    "if pred_pct > 1.5:\n",
    "    print(\"Strong Buy\")\n",
    "elif pred_pct > 0.5:\n",
    "    print(\"Buy\")\n",
    "elif pred_pct < -1.5:\n",
    "    print(\"Strong Sell\")\n",
    "elif pred_pct < -0.5:\n",
    "    print(\"Sell\")\n",
    "else:\n",
    "    print(\"Hold\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
