{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ys8EJg7PLYyC"
      },
      "source": [
        "I chose to make a model that takes in 5 years of stock data and will decide whether to buy, sell, or hold that stock position.\n",
        "\n",
        "I am comparing a baseline Linear NN with two more advanced models to see whether predictions and accuracy improve with more complexity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCSqD4IkoN2c",
        "outputId": "179dd6ae-77a5-4be1-f84a-c44af74da130"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in ./.venv/lib/python3.13/site-packages (2.2.3)\n",
            "Requirement already satisfied: numpy in ./.venv/lib/python3.13/site-packages (2.2.4)\n",
            "Requirement already satisfied: yfinance in ./.venv/lib/python3.13/site-packages (0.2.54)\n",
            "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.13/site-packages (1.6.1)\n",
            "Requirement already satisfied: torch in ./.venv/lib/python3.13/site-packages (2.6.0)\n",
            "Requirement already satisfied: matplotlib in ./.venv/lib/python3.13/site-packages (3.10.1)\n",
            "Requirement already satisfied: seaborn in ./.venv/lib/python3.13/site-packages (0.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.13/site-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.13/site-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: requests>=2.31 in ./.venv/lib/python3.13/site-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in ./.venv/lib/python3.13/site-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in ./.venv/lib/python3.13/site-packages (from yfinance) (4.3.6)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in ./.venv/lib/python3.13/site-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in ./.venv/lib/python3.13/site-packages (from yfinance) (3.17.9)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in ./.venv/lib/python3.13/site-packages (from yfinance) (4.13.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.13/site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in ./.venv/lib/python3.13/site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in ./.venv/lib/python3.13/site-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from torch) (76.0.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.13/site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.13/site-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.13/site-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.13/site-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.13/site-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.13/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests>=2.31->yfinance) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests>=2.31->yfinance) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests>=2.31->yfinance) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas numpy yfinance scikit-learn torch matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "M7dIjfD-oZ4d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import os\n",
        "\n",
        "# For prettier plots\n",
        "plt.style.use('fivethirtyeight')\n",
        "sns.set_theme(style=\"darkgrid\")\n",
        "\n",
        "from enhanced_stock_model import (AttentionLSTM, prepare_data, train_model,\n",
        "                                 evaluate_model, save_model, load_model,\n",
        "                                 predict_next_day)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AD6fo7RWMi6B"
      },
      "source": [
        "# Choose Stock and Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = {\n",
        "    'ticker': 'TSLA',           # Stock to predict\n",
        "    'benchmark': '^GSPC',       # Market benchmark (S&P 500)\n",
        "    'start_date': '2015-01-01', # Training data start date (5+ years for best results)\n",
        "    'seq_length': 30,           # How many trading days to use for each prediction\n",
        "    'hidden_size': 128,         # LSTM hidden layer size\n",
        "    'num_layers': 3,            # Number of stacked LSTM layers\n",
        "    'dropout': 0.4,             # Dropout rate for regularization\n",
        "    'learning_rate': 0.0005,    # Learning rate for optimizer\n",
        "    'batch_size': 64,           # Batch size for training\n",
        "    'num_epochs': 200,          # Maximum number of epochs\n",
        "    'patience': 20              # Early stopping patience\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train, X_test, y_test, scaler, feature_names, close_prices, dates = prepare_data(\n",
        "    ticker=config['ticker'],\n",
        "    benchmark=config['benchmark'],\n",
        "    start_date=config['start_date'],\n",
        "    seq_length=config['seq_length']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: (1948, 30, 42)\n",
            "y_train shape: (1948,)\n",
            "X_test shape: (487, 30, 42)\n",
            "y_test shape: (487,)\n",
            "Number of features: 42\n"
          ]
        }
      ],
      "source": [
        "# Check the shape of our data\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n",
        "print(f\"Number of features: {X_train.shape[2]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5ucuPYbMqGi"
      },
      "source": [
        "# Setup Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0k8mZUqt137"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'StandardScaler' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m features = [\u001b[33m'\u001b[39m\u001b[33mOpen\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mHigh\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mLow\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mClose\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mVolume\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mSP500_Close\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m scaler = \u001b[43mStandardScaler\u001b[49m()\n\u001b[32m      3\u001b[39m X = scaler.fit_transform(data[features])\n\u001b[32m      4\u001b[39m y = data[\u001b[33m'\u001b[39m\u001b[33mLabel\u001b[39m\u001b[33m'\u001b[39m].values\n",
            "\u001b[31mNameError\u001b[39m: name 'StandardScaler' is not defined"
          ]
        }
      ],
      "source": [
        "features = ['Open', 'High', 'Low', 'Close', 'Volume', 'SP500_Close']\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(data[features])\n",
        "y = data['Label'].values\n",
        "\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "batch_size = 1024\n",
        "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP_RJ3sQMfg7"
      },
      "source": [
        "# Baseline Linear Neural Network Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40obro0_Ex9B"
      },
      "outputs": [],
      "source": [
        "class BaseLineNN(nn.Module):\n",
        "    def __init__(self,  input_dim, output_dim):\n",
        "        super(BaseLineNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 16)\n",
        "        self.fc2 = nn.Linear(16, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "input_dim = len(features)\n",
        "output_dim = 3\n",
        "baseline_model = BaseLineNN(input_dim, output_dim)\n",
        "\n",
        "baseline_criterion = nn.CrossEntropyLoss()\n",
        "baseline_optimizer = optim.SGD(baseline_model.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLbbYEhmH3Lv",
        "outputId": "354c3dfa-da79-4d70-c9a6-8c7695e8171d"
      },
      "outputs": [],
      "source": [
        "num_epochs = 1000\n",
        "best_baseline_loss = float(\"inf\")\n",
        "baseline_model_path = \"best_baseline_model.pth\"\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    baseline_model.train()\n",
        "    total_loss = 0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        baseline_optimizer.zero_grad()\n",
        "        outputs = baseline_model(inputs)\n",
        "        loss = baseline_criterion(outputs, labels + 1)\n",
        "        loss.backward()\n",
        "        baseline_optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_train += (predicted == (labels + 1)).sum().item()\n",
        "        total_train += labels.size(0)\n",
        "\n",
        "    train_accuracy = correct_train / total_train\n",
        "\n",
        "    baseline_model.eval()\n",
        "    total_val_loss = 0\n",
        "    correct_test = 0\n",
        "    total_test = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = baseline_model(inputs)\n",
        "            val_loss = baseline_criterion(outputs, labels + 1)\n",
        "            total_val_loss += val_loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct_test += (predicted == (labels + 1)).sum().item()\n",
        "            total_test += labels.size(0)\n",
        "\n",
        "    val_accuracy = correct_test / total_test\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "    avg_val_loss = total_val_loss / len(test_loader)\n",
        "\n",
        "    if avg_val_loss < best_baseline_loss:\n",
        "        best_baseline_loss = avg_val_loss\n",
        "        torch.save(baseline_model.state_dict(), baseline_model_path)\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Baseline Epoch [{epoch+1}/{num_epochs}] | \"\n",
        "              f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {train_accuracy:.4%} | \"\n",
        "              f\"Test Loss: {avg_val_loss:.4f} | Test Acc: {val_accuracy:.4%}\")\n",
        "\n",
        "print(f\"\\nBest baseline model saved to: {baseline_model_path} with Test Loss: {best_baseline_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ir0KMvfLNL6F"
      },
      "source": [
        "# Compare and Evalutate both models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyZPhQn0ulan",
        "outputId": "6b03397f-2f68-47b0-ade7-f6dd182b7c23"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_loader, name=\"Model\"):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            predictions.extend(predicted.numpy())\n",
        "            actuals.extend((labels + 1).numpy())  # Shift back from (-1,0,1) to (0,1,2)\n",
        "\n",
        "    print(f\"{name} Classification Report:\")\n",
        "    print(classification_report(actuals, predictions, target_names=['Sell', 'Hold', 'Buy']))\n",
        "    return predictions, actuals\n",
        "\n",
        "# Evaluate both models\n",
        "predictions_baseline, actuals_baseline = evaluate_model(baseline_model, test_loader, name=\"Baseline NN\")\n",
        "predictions_baseline, actuals_baseline = evaluate_model(mediumClassifier, test_loader, name=\"Baseline NN\")\n",
        "predictions_advanced, actuals_advanced = evaluate_model(improved_model, test_loader, name=\"Advanced NN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nY7Pjlb5uxbz",
        "outputId": "bffef682-a24f-4e75-a3ff-3cee7ea45ff2"
      },
      "outputs": [],
      "source": [
        "latest_data = stock_data.iloc[-1][['Open', 'High', 'Low', 'Close', 'Volume']]\n",
        "latest_sp500 = sp500_data.iloc[-1]['Close']\n",
        "\n",
        "latest_features = np.array([latest_data['Open'], latest_data['High'], latest_data['Low'], latest_data['Close'], latest_data['Volume'], latest_sp500])\n",
        "latest_features = latest_features.reshape(1, -1)\n",
        "latest_features_scaled = scaler.transform(latest_features)\n",
        "latest_tensor = torch.tensor(latest_features_scaled, dtype=torch.float32)\n",
        "\n",
        "baseline_model.eval()\n",
        "with torch.no_grad():\n",
        "    output = baseline_model(latest_tensor)\n",
        "    _, predicted_class = torch.max(output, 1)\n",
        "\n",
        "label_map = {0: \"Sell\", 1: \"Hold\", 2: \"Buy\"}\n",
        "predicted_label = label_map[predicted_class.item()]\n",
        "\n",
        "print(f\"Baseline model: Today's recommended action for {stock_ticker}: {predicted_label}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
